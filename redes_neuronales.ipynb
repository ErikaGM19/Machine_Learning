{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análisis y Comparación de Modelos de Machine Learning: Redes Neuronales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto se busca construir modelos de **Machine Learning** que permitan predecir el estado de aprobación de un préstamo utilizando los atributos de las personas solicitantes. Para ello, se analiza un conjunto de datos que contiene 14 atributos, entre ellos la edad, el ingreso anual, el puntaje crediticio, el propósito del préstamo, entre otros. La etiqueta de clase, loan_status, indica si el préstamo fue aprobado (1) o rechazado (0).\n",
    "\n",
    "Utilizaremos la técnica de **Redes Neuronales** para abodar este problema, variando sus configuraciones y modificando hiperparámetros clave. El objetivo es comparar la exactitud (accuracy) de los modelos generados y determinar cuáles ofrecen mejores predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INTEGRANTES:\n",
    "  1. Marcela Mazo Castro - 1843612\n",
    "  2. Eyder Santiago Suárez Chávez - 2322714\n",
    "  3. Erika García Muñoz - 2259395\n",
    "  4. Juan José Moreno Jaramillo - 2310038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los Datos  \n",
    "En esta sección, se cargan y preparan los datos para el entrenamiento y evaluación de los modelos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Leer el archivo loan_data.csv\n",
    "data = pd.read_csv(\"loan_data.csv\")\n",
    "\n",
    "# Dividir aleatoriamente los datos\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalización y codificación de los datos\n",
    "numerical_features = [\"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\", \"loan_int_rate\", \n",
    "                      \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"]\n",
    "categorical_features = [\"person_gender\", \"person_education\", \"person_home_ownership\", \"loan_intent\", \n",
    "                        \"previous_loan_defaults_on_file\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Redes Neuronales  \n",
    "En esta sección, se construyen y evalúan 5 modelos de redes neuronales variando la cantidad de capas ocultas, el número de neuronas por capa y los hiperparámetros principales como solver y activation. La implementación utiliza la clase MLPClassifier de scikit-learn para entrenar las redes neuronales con diferentes configuraciones topológicas y evaluar su desempeño en términos de exactitud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Construcción de redes neuronales\n",
    "topologies = [\n",
    "    (50,), (100,), (50, 50), (100, 50), (100, 100)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for topology in topologies:\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=topology, random_state=123, max_iter=500))\n",
    "    ])\n",
    "    \n",
    "    # Entrenamiento\n",
    "    model.fit(train_data.drop(columns=\"loan_status\"), train_data[\"loan_status\"])\n",
    "    \n",
    "    # Predicción\n",
    "    predictions = model.predict(test_data.drop(columns=\"loan_status\"))\n",
    "    accuracy = accuracy_score(test_data[\"loan_status\"], predictions)\n",
    "    \n",
    "    results.append({\"Topology\": topology, \"Accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Resultados  \n",
    "Los resultados de las diferentes configuraciones topológicas se resumen en una tabla, mostrando la exactitud alcanzada por cada red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estilos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colors:\n",
    "    HEADER = '\\033[95m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "def print_pretty_table(df, enumerate_rows=False):\n",
    "    if enumerate_rows:\n",
    "        df = df.copy()\n",
    "        df.insert(0, 'Red', range(0, len(df)))\n",
    "\n",
    "    df_formatted = df.copy()\n",
    "    for col in df_formatted.columns:\n",
    "        if col != 'Alpha' and (df_formatted[col].dtype == 'float' or df_formatted[col].dtype == 'int'):\n",
    "            def format_num(x):\n",
    "                if isinstance(x, float):\n",
    "                    return f\"{x:.6f}\"\n",
    "                elif isinstance(x, int):\n",
    "                    return str(x)\n",
    "                else:\n",
    "                    return str(x)\n",
    "            df_formatted[col] = df_formatted[col].apply(format_num)\n",
    "\n",
    "    columns = list(df_formatted.columns)\n",
    "    col_widths = [\n",
    "        max(len(str(item)) for item in [col] + df_formatted[col].astype(str).tolist()) + 2\n",
    "        for col in columns\n",
    "    ]\n",
    "    top_left = '┌'\n",
    "    top_right = '┐'\n",
    "    bottom_left = '└'\n",
    "    bottom_right = '┘'\n",
    "    horizontal = '─'\n",
    "    vertical = '│'\n",
    "    top_sep = '┬'\n",
    "    bottom_sep = '┴'\n",
    "    mid_sep = '┼'\n",
    "    left_sep = '├'\n",
    "    right_sep = '┤'\n",
    "    middle_sep = '┼'\n",
    "\n",
    "    def create_border(left, sep, right):\n",
    "        return left + sep.join([horizontal * width for width in col_widths]) + right\n",
    "\n",
    "    def create_row(items, colored=False):\n",
    "        if colored:\n",
    "            return vertical + vertical.join([\n",
    "                f\"{Colors.BOLD + Colors.YELLOW}{str(item).center(width)}{Colors.ENDC}\"\n",
    "                for item, width in zip(items, col_widths)\n",
    "            ]) + vertical\n",
    "        else:\n",
    "            return vertical + vertical.join([str(item).center(width) for item, width in zip(items, col_widths)]) + vertical\n",
    "\n",
    "    print(create_border(top_left, horizontal, top_right))\n",
    "    print(create_row(columns, colored=True))\n",
    "    print(create_border(left_sep, mid_sep, right_sep))\n",
    "    for i, row_data in df_formatted.iterrows():\n",
    "        if i % 2 == 0:\n",
    "            print(create_row(row_data, colored=False))\n",
    "        else:\n",
    "            row_str = vertical\n",
    "            for item, width in zip(row_data, col_widths):\n",
    "                row_str += f\"\\033[48;5;240m{str(item).center(width)}\\033[0m{vertical}\"\n",
    "            print(row_str)\n",
    "    print(create_border(bottom_left, horizontal, bottom_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla de Resultados:\n",
      "┌─────────────────────────────┐\n",
      "│\u001b[1m\u001b[93m Red \u001b[0m│\u001b[1m\u001b[93m  Topology  \u001b[0m│\u001b[1m\u001b[93m Accuracy \u001b[0m│\n",
      "├─────┼────────────┼──────────┤\n",
      "│  0  │   (50,)    │ 0.923000 │\n",
      "│\u001b[48;5;240m  1  \u001b[0m│\u001b[48;5;240m   (100,)   \u001b[0m│\u001b[48;5;240m 0.919222 \u001b[0m│\n",
      "│  2  │  (50, 50)  │ 0.906667 │\n",
      "│\u001b[48;5;240m  3  \u001b[0m│\u001b[48;5;240m (100, 50)  \u001b[0m│\u001b[48;5;240m 0.903111 \u001b[0m│\n",
      "│  4  │ (100, 100) │ 0.896667 │\n",
      "└─────────────────────────────┘\n",
      "\n",
      "Resultados para diferentes valores de Alpha:\n",
      "┌───────────────────┐\n",
      "│\u001b[1m\u001b[93m Alpha  \u001b[0m│\u001b[1m\u001b[93m Accuracy \u001b[0m│\n",
      "├────────┼──────────┤\n",
      "│ 0.0001 │ 0.903111 │\n",
      "│\u001b[48;5;240m  0.01  \u001b[0m│\u001b[48;5;240m 0.911667 \u001b[0m│\n",
      "└───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "#2 Resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.head(5) \n",
    "\n",
    "print(\"Tabla de Resultados:\")\n",
    "print_pretty_table(results_df, enumerate_rows=True)\n",
    "\n",
    "# 3. Hiperparámetro adicional\n",
    "# Modificar un hiperparámetro adicional ¡Alpha!\n",
    "print(\"\\nResultados para diferentes valores de Alpha:\")\n",
    "alpha_results = []\n",
    "alpha_variations = [0.0001, 0.01]\n",
    "\n",
    "for alpha in alpha_variations:\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(100, 50), random_state=123, max_iter=500, alpha=alpha))\n",
    "    ])\n",
    "    model.fit(train_data.drop(columns=\"loan_status\"), train_data[\"loan_status\"])\n",
    "    predictions = model.predict(test_data.drop(columns=\"loan_status\"))\n",
    "    accuracy = accuracy_score(test_data[\"loan_status\"], predictions)\n",
    "    alpha_results.append({'Alpha': alpha, 'Accuracy': accuracy})\n",
    "\n",
    "alpha_df = pd.DataFrame(alpha_results)\n",
    "print_pretty_table(alpha_df, enumerate_rows=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusiones**\n",
    "\n",
    "En la tabla que se presentó previamente, se observa que la **red neuronal con la siguiente configuración de hiperparámetros** alcanza la mayor exactitud (accuracy):\n",
    "\n",
    "- **Topología:** `(50,)`\n",
    "- **Solver:** `adam` (Por defecto)\n",
    "- **Función de activación:** `relu` (Por defecto)\n",
    "- **Random State:** `123`\n",
    "\n",
    "Esta configuración alcanzó una exactitud de aproximadamente **0.9230**. Por lo tanto, de las cinco topologías evaluadas, la red con **50 neuronas en una capa oculta** ofrece el mejor desempeño con los hiperparámetros actuales.\n",
    "\n",
    "\n",
    "\n",
    "### **Análisis al variar el hiperparámetro `alpha`**\n",
    "\n",
    "Se probaron dos valores de `alpha`: **0.0001** (valor por defecto) y **0.01**, manteniendo el resto de los hiperparámetros iguales a los de la mejor red encontrada. Los resultados son los siguientes:\n",
    "- **alpha=0.0001:** Accuracy ≈ **0.9031**\n",
    "- **alpha=0.01:** Accuracy ≈ **0.9117**\n",
    "\n",
    "Observamos que al **aumentar el valor de `alpha`** de **0.0001** a **0.01**  se mejoró la exactitud del modelo de **0.9031** a **0.9117**, lo que significa que un mayor valor de regularización (`alpha`) ayudó a evitar el sobreajuste, logrando así una **ligera mejora** en el rendimiento del modelo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
