{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análisis y Comparación de Modelos de Machine Learning: Redes Neuronales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto se busca construir modelos de **Machine Learning** que permitan predecir el estado de aprobación de un préstamo utilizando los atributos de las personas solicitantes. Para ello, se analiza un conjunto de datos que contiene 14 atributos, entre ellos la edad, el ingreso anual, el puntaje crediticio, el propósito del préstamo, entre otros. La etiqueta de clase, loan_status, indica si el préstamo fue aprobado (1) o rechazado (0).\n",
    "\n",
    "Utilizaremos la técnica de **Redes Neuronales** para abodar este problema, variando sus configuraciones y modificando hiperparámetros clave. El objetivo es comparar la exactitud (accuracy) de los modelos generados y determinar cuáles ofrecen mejores predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INTEGRANTES:\n",
    "  1. Marcela Mazo Castro - 1843612\n",
    "  2. Eyder Santiago Suárez Chávez - 2322714\n",
    "  3. Erika García Muñoz - 2259395\n",
    "  4. Juan José Moreno Jaramillo - 2310038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los Datos  \n",
    "En esta sección, se cargan y preparan los datos para el entrenamiento y evaluación de los modelos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Leer el archivo loan_data.csv\n",
    "data = pd.read_csv(\"loan_data.csv\")\n",
    "\n",
    "# Dividir aleatoriamente los datos\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalización y codificación de los datos\n",
    "numerical_features = [\"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\", \"loan_int_rate\", \n",
    "                      \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"]\n",
    "categorical_features = [\"person_gender\", \"person_education\", \"person_home_ownership\", \"loan_intent\", \n",
    "                        \"previous_loan_defaults_on_file\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Redes Neuronales  \n",
    "En esta sección, se construyen y evalúan 5 modelos de redes neuronales variando la cantidad de capas ocultas, el número de neuronas por capa y los hiperparámetros principales como solver y activation. La implementación utiliza la clase MLPClassifier de scikit-learn para entrenar las redes neuronales con diferentes configuraciones topológicas y evaluar su desempeño en términos de exactitud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Construcción de redes neuronales\n",
    "topologies = [\n",
    "    (50,), (100,), (50, 50), (100, 50), (100, 100)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for topology in topologies:\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=topology, random_state=123, max_iter=500))\n",
    "    ])\n",
    "    \n",
    "    # Entrenamiento\n",
    "    model.fit(train_data.drop(columns=\"loan_status\"), train_data[\"loan_status\"])\n",
    "    \n",
    "    # Predicción\n",
    "    predictions = model.predict(test_data.drop(columns=\"loan_status\"))\n",
    "    accuracy = accuracy_score(test_data[\"loan_status\"], predictions)\n",
    "    \n",
    "    results.append({\"Topology\": topology, \"Accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Resultados  \n",
    "Los resultados de las diferentes configuraciones topológicas se resumen en una tabla, mostrando la exactitud alcanzada por cada red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2. Tabla de resultados\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mresults\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 3. Hiperparámetro adicional\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Modificar un hiperparámetro adicional (como alpha)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. Tabla de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# 3. Hiperparámetro adicional\n",
    "# Modificar un hiperparámetro adicional (como alpha)\n",
    "alpha_variations = [0.0001, 0.01]\n",
    "\n",
    "for alpha in alpha_variations:\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(100, 50), random_state=123, max_iter=500, alpha=alpha))\n",
    "    ])\n",
    "    \n",
    "    model.fit(train_data.drop(columns=\"loan_status\"), train_data[\"loan_status\"])\n",
    "    predictions = model.predict(test_data.drop(columns=\"loan_status\"))\n",
    "    accuracy = accuracy_score(test_data[\"loan_status\"], predictions)\n",
    "    \n",
    "    print(f\"Alpha: {alpha}, Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
