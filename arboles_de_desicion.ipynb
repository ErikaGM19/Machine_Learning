{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Análisis y Comparación de Modelos de Machine Learning: Árboles de Decisión**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto se busca construir modelos de **Machine Learning** que permitan predecir el estado de aprobación de un préstamo utilizando los atributos de las personas solicitantes. Para ello, se analiza un conjunto de datos que contiene 14 atributos, entre ellos la edad, el ingreso anual, el puntaje crediticio, el propósito del préstamo, entre otros. La etiqueta de clase, loan_status, indica si el préstamo fue aprobado (1) o rechazado (0).\n",
    "\n",
    "Utilizaremos la técnica de **Árboles de Decisión** para abordar este problema, variando sus configuraciones y modificando hiperparámetros clave. El objetivo es comparar la exactitud (accuracy) de los modelos generados y determinar cuáles ofrecen mejores predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INTEGRANTES:\n",
    "  1. Marcela Mazo Castro - 1843612\n",
    "  2. Eyder Santiago Suárez Chávez - 2322714\n",
    "  3. Erika García Muñoz - 2259395\n",
    "  4. Juan José Moreno Jaramillo - 2310038"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los Datos  \n",
    "En esta sección, se cargan y preparan los datos para el entrenamiento y evaluación de los modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Leer el archivo loan_data.csv\n",
    "data = pd.read_csv(\"loan_data.csv\")\n",
    "\n",
    "# Dividir aleatoriamente los datos\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "# Normalización y codificación de los datos\n",
    "numerical_features = [\"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\", \"loan_int_rate\", \n",
    "                      \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"]\n",
    "categorical_features = [\"person_gender\", \"person_education\", \"person_home_ownership\", \"loan_intent\", \n",
    "                        \"previous_loan_defaults_on_file\"]\n",
    "\n",
    "\n",
    "X_train = train_data.drop(columns=\"loan_status\")\n",
    "y_train = train_data[\"loan_status\"]\n",
    "X_test = test_data.drop(columns=\"loan_status\")\n",
    "y_test = test_data[\"loan_status\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Árboles de Decisión  \n",
    "Se construirán y evaluarán 10 árboles de decisión variando el hiperparámetro `max_depth` desde 1 hasta 10, utilizando dos criterios diferentes: `gini` y `entropy`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados con criterion='gini':\n",
      "   Max Depth  Accuracy\n",
      "0          1  0.781778\n",
      "1          2  0.853556\n",
      "2          3  0.902556\n",
      "3          4  0.916444\n",
      "4          5  0.919111\n",
      "5          6  0.919222\n",
      "6          7  0.919556\n",
      "7          8  0.923778\n",
      "8          9  0.923222\n",
      "9         10  0.924444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1 y 2. Leer datos y dividirlos\n",
    "data = pd.read_csv(\"loan_data.csv\")\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "# 3. Normalización y codificación\n",
    "# Reutilizar el preprocessor del notebook anterior\n",
    "\n",
    "# 4. Árboles de decisión con max_depth\n",
    "gini_results = []\n",
    "for depth in range(1, 11):\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", \n",
    "                                              max_depth=depth, random_state=123))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    gini_results.append({\"Max Depth\": depth, \"Accuracy\": accuracy})\n",
    "\n",
    "gini_results_df = pd.DataFrame(gini_results)\n",
    "\n",
    "# ## 5. Incluir en el notebook una tabla con el accuracy para los 10 árboles con criterion=gini\n",
    "print(\"Resultados con criterion='gini':\")\n",
    "print(gini_results_df)\n",
    "\n",
    "# Repetir el proceso con criterion=\"entropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proceso usando el criterio=\"entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados con criterion='entropy':\n",
      "   Max Depth  Accuracy\n",
      "0          1  0.781778\n",
      "1          2  0.853556\n",
      "2          3  0.902556\n",
      "3          4  0.915333\n",
      "4          5  0.916556\n",
      "5          6  0.920444\n",
      "6          7  0.920667\n",
      "7          8  0.923778\n",
      "8          9  0.925222\n",
      "9         10  0.924556\n"
     ]
    }
   ],
   "source": [
    "# ## 6. Repetir el mismo procedimiento con criterion=entropy\n",
    "entropy_results = []\n",
    "for depth in range(1, 11):\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", \n",
    "                                              max_depth=depth, random_state=123))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    entropy_results.append({\"Max Depth\": depth, \"Accuracy\": accuracy})\n",
    "\n",
    "entropy_results_df = pd.DataFrame(entropy_results)\n",
    "\n",
    "# ## 7. Incluir en el notebook una tabla con el accuracy para los 10 árboles con criterion=entropy\n",
    "print(\"\\nResultados con criterion='entropy':\")\n",
    "print(entropy_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados con criterion='gini':\n",
      "   Max Depth  Accuracy\n",
      "0          1  0.781778\n",
      "1          2  0.853556\n",
      "2          3  0.902556\n",
      "3          4  0.916444\n",
      "4          5  0.919111\n",
      "5          6  0.919222\n",
      "6          7  0.919556\n",
      "7          8  0.923778\n",
      "8          9  0.923222\n",
      "9         10  0.924444\n",
      "\n",
      "Resultados con criterion='entropy':\n",
      "   Max Depth  Accuracy\n",
      "0          1  0.781778\n",
      "1          2  0.853556\n",
      "2          3  0.902556\n",
      "3          4  0.915333\n",
      "4          5  0.916556\n",
      "5          6  0.920444\n",
      "6          7  0.920667\n",
      "7          8  0.923778\n",
      "8          9  0.925222\n",
      "9         10  0.924556\n"
     ]
    }
   ],
   "source": [
    "#Estos son los resultados   \n",
    "print(\"Resultados con criterion='gini':\")\n",
    "print(gini_results_df)\n",
    "\n",
    "print(\"\\nResultados con criterion='entropy':\")\n",
    "print(entropy_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores resultados:\n",
      "Mejor resultado con Gini:\n",
      "   Max Depth  Accuracy\n",
      "9         10  0.924444\n",
      "Mejor resultado con Entropy:\n",
      "   Max Depth  Accuracy\n",
      "8          9  0.925222\n",
      "\n",
      "El mejor árbol en general se obtuvo con criterion='entropy', con hiperparámetros:\n",
      "   Max Depth  Accuracy\n",
      "8          9  0.925222\n",
      "\n",
      "Hiperparámetros iniciales con mayor accuracy: criterion=entropy, splitter='best', max_depth=9, random_state=123\n",
      "min_samples_split=2, Accuracy=0.9252222222222222\n",
      "min_samples_split=10, Accuracy=0.9251111111111111\n",
      "\n",
      "Resultados variando min_samples_split:\n",
      "   min_samples_split  Accuracy\n",
      "0                  2  0.925222\n",
      "1                 10  0.925111\n",
      "La exactitud se mantiene igual con min_samples_split=2.0.\n",
      "La exactitud empeora con min_samples_split=10.0.\n",
      "Resultados con criterion='gini':\n",
      "   Max Depth  Accuracy\n",
      "0          1  0.781778\n",
      "1          2  0.853556\n",
      "2          3  0.902556\n",
      "3          4  0.916444\n",
      "4          5  0.919111\n",
      "5          6  0.919222\n",
      "6          7  0.919556\n",
      "7          8  0.923778\n",
      "8          9  0.923222\n",
      "9         10  0.924444\n",
      "\n",
      "Resultados con criterion='entropy':\n",
      "   Max Depth  Accuracy\n",
      "0          1  0.781778\n",
      "1          2  0.853556\n",
      "2          3  0.902556\n",
      "3          4  0.915333\n",
      "4          5  0.916556\n",
      "5          6  0.920444\n",
      "6          7  0.920667\n",
      "7          8  0.923778\n",
      "8          9  0.925222\n",
      "9         10  0.924556\n"
     ]
    }
   ],
   "source": [
    "# ## 8. Indicar los hiperparámetros que permiten obtener el árbol con mayor accuracy\n",
    "# Vamos a encontrar el máximo accuracy entre ambos criterios\n",
    "max_gini_acc = gini_results_df[\"Accuracy\"].max()\n",
    "best_gini = gini_results_df[gini_results_df[\"Accuracy\"] == max_gini_acc]\n",
    "\n",
    "max_entropy_acc = entropy_results_df[\"Accuracy\"].max()\n",
    "best_entropy = entropy_results_df[entropy_results_df[\"Accuracy\"] == max_entropy_acc]\n",
    "\n",
    "print(\"\\nMejores resultados:\")\n",
    "print(\"Mejor resultado con Gini:\")\n",
    "print(best_gini)\n",
    "print(\"Mejor resultado con Entropy:\")\n",
    "print(best_entropy)\n",
    "\n",
    "# Determinamos cuál es el mejor en general\n",
    "if max_gini_acc > max_entropy_acc:\n",
    "    print(\"\\nEl mejor árbol en general se obtuvo con criterion='gini', con hiperparámetros:\")\n",
    "    print(best_gini)\n",
    "else:\n",
    "    print(\"\\nEl mejor árbol en general se obtuvo con criterion='entropy', con hiperparámetros:\")\n",
    "    print(best_entropy)\n",
    "\n",
    "# ## 9. Seleccionar un hiperparámetro diferente a criterion, splitter, max_depth, random_state.\n",
    "# Por ejemplo, usemos el hiperparámetro \"min_samples_split\".\n",
    "# Realizaremos dos variaciones en este hiperparámetro manteniendo los otros que dieron mejor resultado.\n",
    "# Supongamos que el mejor resultado lo obtuvimos con:\n",
    "#   criterion='entropy', splitter='best', random_state=123, max_depth=<donde obtuvimos el mejor>\n",
    "# Vamos a variar el min_samples_split, por ejemplo a 2 y 10.\n",
    "\n",
    "# Identificamos el mejor árbol según el punto 8. Asumamos que el mejor fue con entropy, max_depth=d\n",
    "if max_entropy_acc >= max_gini_acc:\n",
    "    best_criterion = \"entropy\"\n",
    "    best_depth = best_entropy[\"Max Depth\"].values[0]\n",
    "    best_acc = max_entropy_acc\n",
    "else:\n",
    "    best_criterion = \"gini\"\n",
    "    best_depth = best_gini[\"Max Depth\"].values[0]\n",
    "    best_acc = max_gini_acc\n",
    "\n",
    "print(f\"\\nHiperparámetros iniciales con mayor accuracy: criterion={best_criterion}, splitter='best', max_depth={best_depth}, random_state=123\")\n",
    "\n",
    "variations = [2, 10]  # min_samples_split variaciones\n",
    "variation_results = []\n",
    "for mss in variations:\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(criterion=best_criterion, splitter=\"best\", \n",
    "                                              max_depth=best_depth, random_state=123,\n",
    "                                              min_samples_split=mss))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    variation_results.append({\"min_samples_split\": mss, \"Accuracy\": accuracy})\n",
    "    print(f\"min_samples_split={mss}, Accuracy={accuracy}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "var_df = pd.DataFrame(variation_results)\n",
    "print(\"\\nResultados variando min_samples_split:\")\n",
    "print(var_df)\n",
    "\n",
    "\n",
    "\n",
    "# Analizamos si el árbol mejora, empeora o se mantiene\n",
    "for i, row in var_df.iterrows():\n",
    "    if row[\"Accuracy\"] > best_acc:\n",
    "        print(f\"La exactitud mejora con min_samples_split={row['min_samples_split']}.\")\n",
    "    elif row[\"Accuracy\"] < best_acc:\n",
    "        print(f\"La exactitud empeora con min_samples_split={row['min_samples_split']}.\")\n",
    "    else:\n",
    "        print(f\"La exactitud se mantiene igual con min_samples_split={row['min_samples_split']}.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
