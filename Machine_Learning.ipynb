{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Topology  Accuracy\n",
      "0       (50,)  0.923000\n",
      "1      (100,)  0.919222\n",
      "2    (50, 50)  0.906667\n",
      "3   (100, 50)  0.903111\n",
      "4  (100, 100)  0.896667\n",
      "Alpha: 0.0001, Accuracy: 0.9031111111111111\n",
      "Alpha: 0.01, Accuracy: 0.9116666666666666\n"
     ]
    }
   ],
   "source": [
    "# Importación de bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Leer el archivo loan_data.csv\n",
    "data = pd.read_csv(\"loan_data.csv\")\n",
    "\n",
    "# 2. Dividir aleatoriamente los datos\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "# 3. Normalización y codificación\n",
    "numerical_features = [\"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\", \"loan_int_rate\", \n",
    "                      \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"]\n",
    "categorical_features = [\"person_gender\", \"person_education\", \"person_home_ownership\", \"loan_intent\", \n",
    "                        \"previous_loan_defaults_on_file\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])\n",
    "\n",
    "# 4. Construcción de redes neuronales\n",
    "topologies = [\n",
    "    (50,), (100,), (50, 50), (100, 50), (100, 100)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for topology in topologies:\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=topology, random_state=123, max_iter=500))\n",
    "    ])\n",
    "    \n",
    "    # Entrenamiento\n",
    "    model.fit(train_data.drop(columns=\"loan_status\"), train_data[\"loan_status\"])\n",
    "    \n",
    "    # Predicción\n",
    "    predictions = model.predict(test_data.drop(columns=\"loan_status\"))\n",
    "    accuracy = accuracy_score(test_data[\"loan_status\"], predictions)\n",
    "    \n",
    "    results.append({\"Topology\": topology, \"Accuracy\": accuracy})\n",
    "\n",
    "# 5. Tabla de resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# 6. Hiperparámetro adicional\n",
    "# Modificar un hiperparámetro adicional (como alpha)\n",
    "alpha_variations = [0.0001, 0.01]\n",
    "\n",
    "for alpha in alpha_variations:\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', MLPClassifier(hidden_layer_sizes=(100, 50), random_state=123, max_iter=500, alpha=alpha))\n",
    "    ])\n",
    "    \n",
    "    model.fit(train_data.drop(columns=\"loan_status\"), train_data[\"loan_status\"])\n",
    "    predictions = model.predict(test_data.drop(columns=\"loan_status\"))\n",
    "    accuracy = accuracy_score(test_data[\"loan_status\"], predictions)\n",
    "    \n",
    "    print(f\"Alpha: {alpha}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Max Depth  Accuracy\n",
      "0          1  0.781778\n",
      "1          2  0.853556\n",
      "2          3  0.902556\n",
      "3          4  0.916444\n",
      "4          5  0.919111\n",
      "5          6  0.919222\n",
      "6          7  0.919556\n",
      "7          8  0.923778\n",
      "8          9  0.923222\n",
      "9         10  0.924444\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1 y 2. Leer datos y dividirlos\n",
    "data = pd.read_csv(\"loan_data.csv\")\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "# 3. Normalización y codificación\n",
    "# Reutilizar el preprocessor del notebook anterior\n",
    "\n",
    "# 4. Árboles de decisión con max_depth\n",
    "depth_results = []\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=depth, random_state=123))\n",
    "    ])\n",
    "    \n",
    "    model.fit(train_data.drop(columns=\"loan_status\"), train_data[\"loan_status\"])\n",
    "    predictions = model.predict(test_data.drop(columns=\"loan_status\"))\n",
    "    accuracy = accuracy_score(test_data[\"loan_status\"], predictions)\n",
    "    \n",
    "    depth_results.append({\"Max Depth\": depth, \"Accuracy\": accuracy})\n",
    "\n",
    "depth_results_df = pd.DataFrame(depth_results)\n",
    "print(depth_results_df)\n",
    "\n",
    "# Repetir el proceso con criterion=\"entropy\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
